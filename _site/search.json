[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608",
    "section": "",
    "text": "Welcome to the home page for ISSS608 Visual Analytics and Applications."
  },
  {
    "objectID": "index.html#isss608-ay2023-24-january-term",
    "href": "index.html#isss608-ay2023-24-january-term",
    "title": "ISSS608",
    "section": "",
    "text": "Welcome to the home page for ISSS608 Visual Analytics and Applications."
  },
  {
    "objectID": "THE4/Take-home_ex4.html",
    "href": "THE4/Take-home_ex4.html",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "",
    "text": "For this Take Home Exercise, there are several task needs to be done to create the Shiny application.\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\nThis submission includes the prototype report for the group project, which will includes:\n\nthe data preparation process,\nthe selection of data visualization techniques used,\nand the data visualization design and interactivity principles and best practices implemented.\n\nBased on the discussion with team member i will be focusing on the Exploratory Data Analysis & Confirmatory Data Analysis, and the UI design for our Shiny app."
  },
  {
    "objectID": "THE4/Take-home_ex4.html#check-structure-with-glimpse",
    "href": "THE4/Take-home_ex4.html#check-structure-with-glimpse",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.1 Check structure with glimpse()",
    "text": "4.1 Check structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 204,464\nColumns: 15\n$ Station                       &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\"…\n$ Year                          &lt;int&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ Month                         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Day                           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ Daily.Rainfall.Total..mm.     &lt;chr&gt; \"0\", \"0\", \"2.2\", \"0.6\", \"10.5\", \"31.2\", …\n$ Highest.30.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.60.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.120.min.Rainfall..mm. &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Mean.Temperature...C.         &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Maximum.Temperature...C.      &lt;chr&gt; \"29.5\", \"31.7\", \"31.1\", \"32.3\", \"27\", \"2…\n$ Minimum.Temperature...C.      &lt;chr&gt; \"24.8\", \"25\", \"25.1\", \"23.7\", \"23.8\", \"2…\n$ Mean.Wind.Speed..km.h.        &lt;chr&gt; \"15.8\", \"16.5\", \"14.9\", \"8.9\", \"11.9\", \"…\n$ Max.Wind.Speed..km.h.         &lt;chr&gt; \"35.3\", \"37.1\", \"33.5\", \"35.3\", \"33.5\", …\n$ Latitude                      &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524, …\n$ Longitude                     &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007, …\n\n\nThere are 204464 rows, and 15 columns in the dataset. We see that there are missing values shown as ‘?’ in the dataset. In the next few steps, we will drop specific columns and rows based on the project focus."
  },
  {
    "objectID": "THE4/Take-home_ex4.html#drop-unused-columns",
    "href": "THE4/Take-home_ex4.html#drop-unused-columns",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.2 Drop unused columns",
    "text": "4.2 Drop unused columns\nWe will not be using all 15 columns for this project. The following columns will be dropped:\n\nHighest 30 Min Rainfall (mm)\nHighest 60 Min Rainfall (mm)\nHighest 1200 Min Rainfall (mm)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  select(-c(`Highest.30.min.Rainfall..mm.`, \n            `Highest.60.min.Rainfall..mm.`, \n            `Highest.120.min.Rainfall..mm.`,\n            `Mean.Wind.Speed..km.h.`,\n            `Max.Wind.Speed..km.h.`))"
  },
  {
    "objectID": "THE4/Take-home_ex4.html#remove-rows-for-specific-stations",
    "href": "THE4/Take-home_ex4.html#remove-rows-for-specific-stations",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.3 Remove rows for specific Stations",
    "text": "4.3 Remove rows for specific Stations\nThe Meteorological Service Singapore also provides a file, Station Records that has some information on the availability of data for each station. After examining the station records file, we found that 41 stations had missing information for some variables. We will hence drop rows for these stations.\n\n# Drop rows of 41 stations\n# Define the station names to remove\nstations_to_remove &lt;- c(\"Macritchie Reservoir\", \"Lower Peirce Reservoir\", \"Pasir Ris (West)\", \"Kampong Bahru\", \"Jurong Pier\", \"Ulu Pandan\", \"Serangoon\", \"Jurong (East)\", \"Mandai\", \"Upper Thomson\", \"Buangkok\", \"Boon Lay (West)\", \"Bukit Panjang\", \"Kranji Reservoir\", \"Tanjong Pagar\", \"Admiralty West\", \"Queenstown\", \"Tanjong Katong\", \"Chai Chee\", \"Upper Peirce Reservoir\", \"Kent Ridge\", \"Somerset (Road)\", \"Punggol\", \"Tuas West\", \"Simei\", \"Toa Payoh\", \"Tuas\", \"Bukit Timah\", \"Yishun\", \"Buona Vista\", \"Pasir Ris (Central)\", \"Jurong (North)\", \"Choa Chu Kang (West)\", \"Serangoon North\", \"Lim Chu Kang\", \"Marine Parade\", \"Choa Chu Kang (Central)\", \"Dhoby Ghaut\", \"Nicoll Highway\", \"Botanic Garden\", \"Whampoa\")\n\n# Remove rows with the specified station names\nraw_weather_data &lt;- raw_weather_data[!raw_weather_data$Station %in% stations_to_remove, ]\n\n# Print the number of stations left\nprint(sprintf(\" %d stations removed. %d stations left.\", length(stations_to_remove), n_distinct(raw_weather_data$Station)))\n\n[1] \" 41 stations removed. 22 stations left.\""
  },
  {
    "objectID": "THE4/Take-home_ex4.html#check-for-duplicates",
    "href": "THE4/Take-home_ex4.html#check-for-duplicates",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.4 Check for duplicates",
    "text": "4.4 Check for duplicates\n\n# Identify duplicates\nduplicates &lt;- raw_weather_data[duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")]) | duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")], fromLast = TRUE), ]\n\n# Check if 'duplicates' dataframe is empty\nif (nrow(duplicates) == 0) {\n  print(\"The combination of Station Name, Year, Month, and Day is unique.\")\n} else {\n  print(\"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\")\n  print(duplicates)\n}\n\n[1] \"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\"\n               Station Year Month Day Daily.Rainfall.Total..mm.\n13381   Semakau Island   NA    NA  NA                         -\n13382   Semakau Island   NA    NA  NA                         -\n13383   Semakau Island   NA    NA  NA                         -\n13384   Semakau Island   NA    NA  NA                         -\n13385   Semakau Island   NA    NA  NA                         -\n13386   Semakau Island   NA    NA  NA                         -\n13387   Semakau Island   NA    NA  NA                         -\n13388   Semakau Island   NA    NA  NA                         -\n13389   Semakau Island   NA    NA  NA                         -\n13390   Semakau Island   NA    NA  NA                         -\n13391   Semakau Island   NA    NA  NA                         -\n13392   Semakau Island   NA    NA  NA                         -\n13393   Semakau Island   NA    NA  NA                         -\n13394   Semakau Island   NA    NA  NA                         -\n13395   Semakau Island   NA    NA  NA                         -\n13396   Semakau Island   NA    NA  NA                         -\n13397   Semakau Island   NA    NA  NA                         -\n13398   Semakau Island   NA    NA  NA                         -\n13399   Semakau Island   NA    NA  NA                         -\n13400   Semakau Island   NA    NA  NA                         -\n13401   Semakau Island   NA    NA  NA                         -\n13402   Semakau Island   NA    NA  NA                         -\n13403   Semakau Island   NA    NA  NA                         -\n13404   Semakau Island   NA    NA  NA                         -\n13405   Semakau Island   NA    NA  NA                         -\n13406   Semakau Island   NA    NA  NA                         -\n13407   Semakau Island   NA    NA  NA                         -\n13408   Semakau Island   NA    NA  NA                         -\n13409   Semakau Island   NA    NA  NA                         -\n13410   Semakau Island   NA    NA  NA                         -\n13411   Semakau Island   NA    NA  NA                         -\n13412   Semakau Island   NA    NA  NA                         -\n13413   Semakau Island   NA    NA  NA                         -\n13414   Semakau Island   NA    NA  NA                         -\n13415   Semakau Island   NA    NA  NA                         -\n13416   Semakau Island   NA    NA  NA                         -\n13417   Semakau Island   NA    NA  NA                         -\n13418   Semakau Island   NA    NA  NA                         -\n13419   Semakau Island   NA    NA  NA                         -\n13420   Semakau Island   NA    NA  NA                         -\n13421   Semakau Island   NA    NA  NA                         -\n13422   Semakau Island   NA    NA  NA                         -\n13423   Semakau Island   NA    NA  NA                         -\n13424   Semakau Island   NA    NA  NA                         -\n13425   Semakau Island   NA    NA  NA                         -\n13426   Semakau Island   NA    NA  NA                         -\n13427   Semakau Island   NA    NA  NA                         -\n13428   Semakau Island   NA    NA  NA                         -\n13429   Semakau Island   NA    NA  NA                         -\n13430   Semakau Island   NA    NA  NA                         -\n13431   Semakau Island   NA    NA  NA                         -\n13432   Semakau Island   NA    NA  NA                         -\n13433   Semakau Island   NA    NA  NA                         -\n13434   Semakau Island   NA    NA  NA                         -\n13435   Semakau Island   NA    NA  NA                         -\n13436   Semakau Island   NA    NA  NA                         -\n13437   Semakau Island   NA    NA  NA                         -\n13438   Semakau Island   NA    NA  NA                         -\n13439   Semakau Island   NA    NA  NA                         -\n13440   Semakau Island   NA    NA  NA                         -\n13441   Semakau Island   NA    NA  NA                         -\n14084   Semakau Island   NA    NA  NA                         -\n14085   Semakau Island   NA    NA  NA                         -\n14086   Semakau Island   NA    NA  NA                         -\n14087   Semakau Island   NA    NA  NA                         -\n14088   Semakau Island   NA    NA  NA                         -\n183829 Boon Lay (East)   NA    NA  NA                         -\n183830 Boon Lay (East)   NA    NA  NA                         -\n183831 Boon Lay (East)   NA    NA  NA                         -\n183832 Boon Lay (East)   NA    NA  NA                         -\n183833 Boon Lay (East)   NA    NA  NA                         -\n183834 Boon Lay (East)   NA    NA  NA                         -\n183835 Boon Lay (East)   NA    NA  NA                         -\n183836 Boon Lay (East)   NA    NA  NA                         -\n183837 Boon Lay (East)   NA    NA  NA                         -\n183838 Boon Lay (East)   NA    NA  NA                         -\n183839 Boon Lay (East)   NA    NA  NA                         -\n183840 Boon Lay (East)   NA    NA  NA                         -\n183841 Boon Lay (East)   NA    NA  NA                         -\n183842 Boon Lay (East)   NA    NA  NA                         -\n183843 Boon Lay (East)   NA    NA  NA                         -\n183844 Boon Lay (East)   NA    NA  NA                         -\n183845 Boon Lay (East)   NA    NA  NA                         -\n183846 Boon Lay (East)   NA    NA  NA                         -\n183847 Boon Lay (East)   NA    NA  NA                         -\n183848 Boon Lay (East)   NA    NA  NA                         -\n183849 Boon Lay (East)   NA    NA  NA                         -\n183850 Boon Lay (East)   NA    NA  NA                         -\n183851 Boon Lay (East)   NA    NA  NA                         -\n183852 Boon Lay (East)   NA    NA  NA                         -\n183853 Boon Lay (East)   NA    NA  NA                         -\n183854 Boon Lay (East)   NA    NA  NA                         -\n183855 Boon Lay (East)   NA    NA  NA                         -\n183856 Boon Lay (East)   NA    NA  NA                         -\n183857 Boon Lay (East)   NA    NA  NA                         -\n183858 Boon Lay (East)   NA    NA  NA                         -\n191071 Boon Lay (East)   NA    NA  NA                         -\n191072 Boon Lay (East)   NA    NA  NA                         -\n191073 Boon Lay (East)   NA    NA  NA                         -\n191074 Boon Lay (East)   NA    NA  NA                         -\n191075 Boon Lay (East)   NA    NA  NA                         -\n191076 Boon Lay (East)   NA    NA  NA                         -\n191077 Boon Lay (East)   NA    NA  NA                         -\n191078 Boon Lay (East)   NA    NA  NA                         -\n191079 Boon Lay (East)   NA    NA  NA                         -\n191080 Boon Lay (East)   NA    NA  NA                         -\n191081 Boon Lay (East)   NA    NA  NA                         -\n191082 Boon Lay (East)   NA    NA  NA                         -\n191083 Boon Lay (East)   NA    NA  NA                         -\n191084 Boon Lay (East)   NA    NA  NA                         -\n191085 Boon Lay (East)   NA    NA  NA                         -\n191086 Boon Lay (East)   NA    NA  NA                         -\n191087 Boon Lay (East)   NA    NA  NA                         -\n191088 Boon Lay (East)   NA    NA  NA                         -\n191089 Boon Lay (East)   NA    NA  NA                         -\n191090 Boon Lay (East)   NA    NA  NA                         -\n191091 Boon Lay (East)   NA    NA  NA                         -\n191092 Boon Lay (East)   NA    NA  NA                         -\n191093 Boon Lay (East)   NA    NA  NA                         -\n191094 Boon Lay (East)   NA    NA  NA                         -\n191095 Boon Lay (East)   NA    NA  NA                         -\n191096 Boon Lay (East)   NA    NA  NA                         -\n191097 Boon Lay (East)   NA    NA  NA                         -\n191098 Boon Lay (East)   NA    NA  NA                         -\n191099 Boon Lay (East)   NA    NA  NA                         -\n191100 Boon Lay (East)   NA    NA  NA                         -\n191101 Boon Lay (East)   NA    NA  NA                         -\n       Mean.Temperature...C. Maximum.Temperature...C. Minimum.Temperature...C.\n13381                      -                        -                        -\n13382                      -                        -                        -\n13383                      -                        -                        -\n13384                      -                        -                        -\n13385                      -                        -                        -\n13386                      -                        -                        -\n13387                      -                        -                        -\n13388                      -                        -                        -\n13389                      -                        -                        -\n13390                      -                        -                        -\n13391                      -                        -                        -\n13392                      -                        -                        -\n13393                      -                        -                        -\n13394                      -                        -                        -\n13395                      -                        -                        -\n13396                      -                        -                        -\n13397                      -                        -                        -\n13398                      -                        -                        -\n13399                      -                        -                        -\n13400                      -                        -                        -\n13401                      -                        -                        -\n13402                      -                        -                        -\n13403                      -                        -                        -\n13404                      -                        -                        -\n13405                      -                        -                        -\n13406                      -                        -                        -\n13407                      -                        -                        -\n13408                      -                        -                        -\n13409                      -                        -                        -\n13410                      -                        -                        -\n13411                      -                        -                        -\n13412                      -                        -                        -\n13413                      -                        -                        -\n13414                      -                        -                        -\n13415                      -                        -                        -\n13416                      -                        -                        -\n13417                      -                        -                        -\n13418                      -                        -                        -\n13419                      -                        -                        -\n13420                      -                        -                        -\n13421                      -                        -                        -\n13422                      -                        -                        -\n13423                      -                        -                        -\n13424                      -                        -                        -\n13425                      -                        -                        -\n13426                      -                        -                        -\n13427                      -                        -                        -\n13428                      -                        -                        -\n13429                      -                        -                        -\n13430                      -                        -                        -\n13431                      -                        -                        -\n13432                      -                        -                        -\n13433                      -                        -                        -\n13434                      -                        -                        -\n13435                      -                        -                        -\n13436                      -                        -                        -\n13437                      -                        -                        -\n13438                      -                        -                        -\n13439                      -                        -                        -\n13440                      -                        -                        -\n13441                      -                        -                        -\n14084                      -                        -                        -\n14085                      -                        -                        -\n14086                      -                        -                        -\n14087                      -                        -                        -\n14088                      -                        -                        -\n183829                     -                        -                        -\n183830                     -                        -                        -\n183831                     -                        -                        -\n183832                     -                        -                        -\n183833                     -                        -                        -\n183834                     -                        -                        -\n183835                     -                        -                        -\n183836                     -                        -                        -\n183837                     -                        -                        -\n183838                     -                        -                        -\n183839                     -                        -                        -\n183840                     -                        -                        -\n183841                     -                        -                        -\n183842                     -                        -                        -\n183843                     -                        -                        -\n183844                     -                        -                        -\n183845                     -                        -                        -\n183846                     -                        -                        -\n183847                     -                        -                        -\n183848                     -                        -                        -\n183849                     -                        -                        -\n183850                     -                        -                        -\n183851                     -                        -                        -\n183852                     -                        -                        -\n183853                     -                        -                        -\n183854                     -                        -                        -\n183855                     -                        -                        -\n183856                     -                        -                        -\n183857                     -                        -                        -\n183858                     -                        -                        -\n191071                     -                        -                        -\n191072                     -                        -                        -\n191073                     -                        -                        -\n191074                     -                        -                        -\n191075                     -                        -                        -\n191076                     -                        -                        -\n191077                     -                        -                        -\n191078                     -                        -                        -\n191079                     -                        -                        -\n191080                     -                        -                        -\n191081                     -                        -                        -\n191082                     -                        -                        -\n191083                     -                        -                        -\n191084                     -                        -                        -\n191085                     -                        -                        -\n191086                     -                        -                        -\n191087                     -                        -                        -\n191088                     -                        -                        -\n191089                     -                        -                        -\n191090                     -                        -                        -\n191091                     -                        -                        -\n191092                     -                        -                        -\n191093                     -                        -                        -\n191094                     -                        -                        -\n191095                     -                        -                        -\n191096                     -                        -                        -\n191097                     -                        -                        -\n191098                     -                        -                        -\n191099                     -                        -                        -\n191100                     -                        -                        -\n191101                     -                        -                        -\n       Latitude Longitude\n13381    1.1890  103.7680\n13382    1.1890  103.7680\n13383    1.1890  103.7680\n13384    1.1890  103.7680\n13385    1.1890  103.7680\n13386    1.1890  103.7680\n13387    1.1890  103.7680\n13388    1.1890  103.7680\n13389    1.1890  103.7680\n13390    1.1890  103.7680\n13391    1.1890  103.7680\n13392    1.1890  103.7680\n13393    1.1890  103.7680\n13394    1.1890  103.7680\n13395    1.1890  103.7680\n13396    1.1890  103.7680\n13397    1.1890  103.7680\n13398    1.1890  103.7680\n13399    1.1890  103.7680\n13400    1.1890  103.7680\n13401    1.1890  103.7680\n13402    1.1890  103.7680\n13403    1.1890  103.7680\n13404    1.1890  103.7680\n13405    1.1890  103.7680\n13406    1.1890  103.7680\n13407    1.1890  103.7680\n13408    1.1890  103.7680\n13409    1.1890  103.7680\n13410    1.1890  103.7680\n13411    1.1890  103.7680\n13412    1.1890  103.7680\n13413    1.1890  103.7680\n13414    1.1890  103.7680\n13415    1.1890  103.7680\n13416    1.1890  103.7680\n13417    1.1890  103.7680\n13418    1.1890  103.7680\n13419    1.1890  103.7680\n13420    1.1890  103.7680\n13421    1.1890  103.7680\n13422    1.1890  103.7680\n13423    1.1890  103.7680\n13424    1.1890  103.7680\n13425    1.1890  103.7680\n13426    1.1890  103.7680\n13427    1.1890  103.7680\n13428    1.1890  103.7680\n13429    1.1890  103.7680\n13430    1.1890  103.7680\n13431    1.1890  103.7680\n13432    1.1890  103.7680\n13433    1.1890  103.7680\n13434    1.1890  103.7680\n13435    1.1890  103.7680\n13436    1.1890  103.7680\n13437    1.1890  103.7680\n13438    1.1890  103.7680\n13439    1.1890  103.7680\n13440    1.1890  103.7680\n13441    1.1890  103.7680\n14084    1.1890  103.7680\n14085    1.1890  103.7680\n14086    1.1890  103.7680\n14087    1.1890  103.7680\n14088    1.1890  103.7680\n183829   1.3302  103.7205\n183830   1.3302  103.7205\n183831   1.3302  103.7205\n183832   1.3302  103.7205\n183833   1.3302  103.7205\n183834   1.3302  103.7205\n183835   1.3302  103.7205\n183836   1.3302  103.7205\n183837   1.3302  103.7205\n183838   1.3302  103.7205\n183839   1.3302  103.7205\n183840   1.3302  103.7205\n183841   1.3302  103.7205\n183842   1.3302  103.7205\n183843   1.3302  103.7205\n183844   1.3302  103.7205\n183845   1.3302  103.7205\n183846   1.3302  103.7205\n183847   1.3302  103.7205\n183848   1.3302  103.7205\n183849   1.3302  103.7205\n183850   1.3302  103.7205\n183851   1.3302  103.7205\n183852   1.3302  103.7205\n183853   1.3302  103.7205\n183854   1.3302  103.7205\n183855   1.3302  103.7205\n183856   1.3302  103.7205\n183857   1.3302  103.7205\n183858   1.3302  103.7205\n191071   1.3302  103.7205\n191072   1.3302  103.7205\n191073   1.3302  103.7205\n191074   1.3302  103.7205\n191075   1.3302  103.7205\n191076   1.3302  103.7205\n191077   1.3302  103.7205\n191078   1.3302  103.7205\n191079   1.3302  103.7205\n191080   1.3302  103.7205\n191081   1.3302  103.7205\n191082   1.3302  103.7205\n191083   1.3302  103.7205\n191084   1.3302  103.7205\n191085   1.3302  103.7205\n191086   1.3302  103.7205\n191087   1.3302  103.7205\n191088   1.3302  103.7205\n191089   1.3302  103.7205\n191090   1.3302  103.7205\n191091   1.3302  103.7205\n191092   1.3302  103.7205\n191093   1.3302  103.7205\n191094   1.3302  103.7205\n191095   1.3302  103.7205\n191096   1.3302  103.7205\n191097   1.3302  103.7205\n191098   1.3302  103.7205\n191099   1.3302  103.7205\n191100   1.3302  103.7205\n191101   1.3302  103.7205"
  },
  {
    "objectID": "THE4/Take-home_ex4.html#check-and-handle-missing-values",
    "href": "THE4/Take-home_ex4.html#check-and-handle-missing-values",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.5 Check and handle missing values",
    "text": "4.5 Check and handle missing values\n\n4.5.1 First check for missing values\nMissing values in this dataset can be represented by:\n\n\\u0097\nNA\n-\n\nWe first replace these values with actual NA values:\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"\\u0097\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"NA\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"-\")))\n\nNext, we visualize the missing values in the dataset:\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see there is quite a number of missing data in the Mean Temperature, Minimum Temperature, Maximum Temperature and Daily Rainfall Total. We will take steps to handle the missing data.\n\n\n4.5.2 Remove Stations with significant missing data\nWe have identified two checks to make:\n\nCheck which stations have no recorded data for entire months.\nCheck which stations have more than 7 consecutive days of missing data\n\nFor both these checks, we will remove the entire station from the dataset as it would not be practical to impute such large amounts of missing values.\n\n4.5.3 Identify and remove Stations with no recorded data for entire months\nSome stations have no recorded data for entire months, as summarised in the table below:\n\n# Create complete combination of Station, Year, and Month\nall_combinations &lt;- expand.grid(\n  Station = unique(raw_weather_data$Station),\n  Year = 2021:2023,\n  Month = 1:12\n)\n\n# Left join this with the original weather data to identify missing entries\nmissing_months &lt;- all_combinations %&gt;%\n  left_join(raw_weather_data, by = c(\"Station\", \"Year\", \"Month\")) %&gt;%\n  # Use is.na() to check for rows that didn't have a match in the original data\n  filter(is.na(Day)) %&gt;%\n  # Select only the relevant columns for the final output\n  select(Station, Year, Month)\n\n# Create a summary table that lists out the missing months\nmissing_months_summary &lt;- missing_months %&gt;%\n  group_by(Station, Year) %&gt;%\n  summarise(MissingMonths = toString(sort(unique(Month))), .groups = 'drop')\n\nkable(missing_months_summary)\n\n\n\n\nStation\nYear\nMissingMonths\n\n\n\n\nBoon Lay (East)\n2021\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, missing_months, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(missing_months$Station), paste(unique(missing_months$Station), collapse = \", \")))\n\n[1] \"The folowing 2 stations were dropped: Boon Lay (East), Khatib\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 20 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nNewton\n\n\n9\nJurong Island\n\n\n10\nTuas South\n\n\n11\nPasir Panjang\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nChangi\n\n\n15\nSeletar\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang\n\n\n\n\n\n\n\n4.5.4 Identify and remove Stations with excessive missing values\nIf there are any missing values, we can try to impute these missing values. However, if there are 7 or more consecutive values missing, we will remove these stations first.\n\n# Define a helper function to count the number of 7 or more consecutive NAs\ncount_seven_consecutive_NAs &lt;- function(x) {\n  na_runs &lt;- rle(is.na(x))\n  total_consecutive_NAs &lt;- sum(na_runs$lengths[na_runs$values & na_runs$lengths &gt;= 7])\n  return(total_consecutive_NAs)\n}\n\n# Apply the helper function to each relevant column within grouped data\nweather_summary &lt;- raw_weather_data %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(across(-Day, ~ count_seven_consecutive_NAs(.x), .names = \"count_consec_NAs_{.col}\"), .groups = \"drop\")\n\n# Filter to keep only rows where there is at least one column with 7 or more consecutive missing values\nweather_summary_with_consecutive_NAs &lt;- weather_summary %&gt;%\n  filter(if_any(starts_with(\"count_consec_NAs_\"), ~ . &gt; 0))\n\n# View the result\nprint(sprintf(\"There are %d stations with 7 or more consecutive missing values.\", n_distinct(weather_summary_with_consecutive_NAs$Station)))\n\n[1] \"There are 13 stations with 7 or more consecutive missing values.\"\n\n\n\n# kable(weather_summary_with_consecutive_NAs)\ndatatable(weather_summary_with_consecutive_NAs, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Details of stations with &gt;=7 missing values')\n\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, weather_summary_with_consecutive_NAs, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(weather_summary_with_consecutive_NAs$Station), paste(unique(weather_summary_with_consecutive_NAs$Station), collapse = \", \")))\n\n[1] \"The folowing 13 stations were dropped: Admiralty, Ang Mo Kio, Clementi, Jurong Island, Marina Barrage, Paya Lebar, Pulau Ubin, Seletar, Semakau Island, Sembawang, Sentosa Island, Tengah, Tuas South\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 7 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nEast Coast Parkway\n\n\n2\nNewton\n\n\n3\nPasir Panjang\n\n\n4\nChoa Chu Kang (South)\n\n\n5\nChangi\n\n\n6\nTai Seng\n\n\n7\nJurong (West)\n\n\n\n\n\n\n\n\n4.5.5 Second check for missing values\nFrom the check below we see there are still missing values in our data. We will impute these values in the next step.\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see that there is still a few missing values from the selected stations.\n\n\n4.6 Impute missing values\nTo handle the missing values for the remaining Stations, we will impute missing values using simple moving average from imputeTS package.\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, Day, sep = \"-\"))) %&gt;%\n  relocate(Date, .after = 1)\n\n\n# Define the weather variables to loop through\nweather_variables &lt;- c(\"Daily.Rainfall.Total..mm.\", \"Mean.Temperature...C.\", \"Maximum.Temperature...C.\", \"Minimum.Temperature...C.\")\n\n# Ensure raw_weather_data is correctly copied to a new data frame for imputation\nweather_data_imputed &lt;- raw_weather_data\n\n# Loop through each weather variable to impute missing values\nfor(variable in weather_variables) {\n  # Convert variable to numeric, ensuring that the conversion warnings are handled if necessary\n  weather_data_imputed[[variable]] &lt;- as.numeric(as.character(weather_data_imputed[[variable]]))\n  \n  # Impute missing values using a moving average\n  weather_data_imputed &lt;- weather_data_imputed %&gt;%\n    group_by(Station) %&gt;%\n    arrange(Station, Date) %&gt;%\n    mutate(\"{variable}\" := round(na_ma(.data[[variable]], k = 7, weighting = \"simple\"), 1)) %&gt;%\n    ungroup()\n}\n\n\n\n4.7 Add specific columns to data [NEW]\nThese columns are added as they may be used in plots later.\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;% \n  mutate(Date_mine = make_date(2023, month(Date), day(Date)),\n         Month_Name = factor(months(Date), levels = month.name),\n         Week = isoweek(Date),\n         Weekday = wday(Date)\n  )"
  },
  {
    "objectID": "THE4/Take-home_ex4.html#summary-of-cleaned-data",
    "href": "THE4/Take-home_ex4.html#summary-of-cleaned-data",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "4.8 Summary of cleaned data",
    "text": "4.8 Summary of cleaned data\n\nDetails of stations and time period of data\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2024-01-31 \n\n\nbut i only want to keep until 2023, exclude record in 2024\n\nweather_data_imputed &lt;- subset(weather_data_imputed, Date &lt;= as.Date(\"2023-12-31\"))\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2023-12-31 \n\n\nAnd also to ease further analysis, convert year, month, day to factor data type:\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;%\n  mutate_at(vars(Year,Month,Day),as.factor)\n\nglimpse(weather_data_imputed)\n\nRows: 25,258\nColumns: 15\n$ Station                   &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Cha…\n$ Date                      &lt;date&gt; 2014-01-01, 2014-01-02, 2014-01-03, 2014-01…\n$ Year                      &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 20…\n$ Month                     &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Day                       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ Daily.Rainfall.Total..mm. &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 18.4, 31.2, 0.0, 0.0, 2.…\n$ Mean.Temperature...C.     &lt;dbl&gt; 26.7, 27.4, 27.1, 27.1, 24.8, 25.3, 26.7, 27…\n$ Maximum.Temperature...C.  &lt;dbl&gt; 29.0, 30.9, 30.4, 31.1, 26.4, 27.1, 30.7, 31…\n$ Minimum.Temperature...C.  &lt;dbl&gt; 24.9, 25.0, 24.9, 24.9, 23.3, 23.9, 24.3, 24…\n$ Latitude                  &lt;dbl&gt; 1.3678, 1.3678, 1.3678, 1.3678, 1.3678, 1.36…\n$ Longitude                 &lt;dbl&gt; 103.9826, 103.9826, 103.9826, 103.9826, 103.…\n$ Date_mine                 &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ Month_Name                &lt;fct&gt; January, January, January, January, January,…\n$ Week                      &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,…\n$ Weekday                   &lt;dbl&gt; 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4,…\n\n\n\nkable(unique(weather_data_imputed$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Stations\")\n\n\nList of Stations\n\n\n\nStation\n\n\n\n\n1\nChangi\n\n\n2\nChoa Chu Kang (South)\n\n\n3\nEast Coast Parkway\n\n\n4\nJurong (West)\n\n\n5\nNewton\n\n\n6\nPasir Panjang\n\n\n7\nTai Seng\n\n\n\n\n\n\n\nView dataset as interactive table\n\ndatatable(weather_data_imputed, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Cleaned and imputed weather dataset')\n\n\n\n\n\n\n\ncolnames(weather_data_imputed)[6] &lt;- \"Daily_Rainfall_Total_mm\"\ncolnames(weather_data_imputed)[7] &lt;- \"Mean_Temperature\"\ncolnames(weather_data_imputed)[8] &lt;- \"Max_Temperature\"\ncolnames(weather_data_imputed)[9] &lt;- \"Min_Temperature\""
  },
  {
    "objectID": "THE4/Take-home_ex4.html#cda-hypothesis",
    "href": "THE4/Take-home_ex4.html#cda-hypothesis",
    "title": "Take-home exercise 4 Visual Analytics",
    "section": "5.2 CDA Hypothesis",
    "text": "5.2 CDA Hypothesis\nThis confirmatory data analysis section will check the data based on the certain hypothesis made from the exploratory & descriptive analysis in the above sections.\nAs of now, two hypothesis are made:\n\nDoes Singapore’s weather change across different years shows statistical significant?\ncan we clearly identify the ‘dry’ and ‘wet’ month?\n\n\n5.2.1Does Singapore’s Weather Change Across Different Years Shows Statistical Significant?\nIn this part, the weather change accounts for both the temperature and the rainfall as given in the data used.\n\n5.2.1.1 Temperature\n\ntemp_year1 &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_year1,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(temp_year1)\n\nRows: 70\nColumns: 5\nGroups: Station [7]\n$ Station          &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Ch…\n$ Year             &lt;fct&gt; 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022,…\n$ median_mean_temp &lt;dbl&gt; 28.00, 28.40, 28.60, 27.70, 27.90, 28.60, 28.10, 28.0…\n$ median_max_temp  &lt;dbl&gt; 31.9, 32.0, 32.1, 31.3, 31.9, 32.6, 31.9, 32.1, 31.8,…\n$ median_min_temp  &lt;dbl&gt; 25.20, 25.80, 25.90, 25.10, 25.40, 26.00, 25.40, 25.2…\n\n\nSave the output as csv:\n\nwrite_csv(temp_year1, \"data/temp_year1.csv\")\n\nTo check out the median mean, max and min temperature:\n\nMedian Daily Mean TemperatureMedian Daily MAX TemperatureMedian Daily MIN Temperature\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_mean_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_mean_temp)) %&gt;%\n    layout(title = paste(\"Median Mean Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np2 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np2 &lt;- layout(p2,\n                       title = \"Median Daily Mean Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np2\n\n\n\n\n\nBased on the line graph, we can not say that there the mean temperature across selected weather stations have significant changes from year 2014 to 2023.\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_max_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_max_temp)) %&gt;%\n    layout(title = paste(\"Median Max Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np3 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np3 &lt;- layout(p3,\n                       title = \"Median Daily Maximum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np3\n\n\n\n\n\n\n\n\np4 &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_min_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_min_temp)) %&gt;%\n    layout(title = paste(\"Median Min Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np4 &lt;- subplot(p4, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np4 &lt;- layout(p4,\n                       title = \"Median Daily Minimum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np4\n\n\n\n\n\n\n\n\nBefore performing statistical test on the significant level, is best to determine how the temperature data is distributed in the data. We can observe the normality of the data using ridgeline plots, using the code chunk below:\n\nNormality Daily Mean TemperatureNormality Daily Max TemperatureNormality Daily Min Temperature\n\n\n\np5 &lt;- ggplot(weather_data_imputed, \n       aes(x = Mean_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\") +\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12) + # Adjusted for smaller text\n  coord_cartesian(xlim = c(0,50)) +\n  labs(title=\"Distribution of Mean Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Mean Temperature (°C)\")\n\np5\n\n\n\n\nBased on the above observation, as the mean temperature is not normally distributed, non-parametric test will be used.\n\n\n\np6 &lt;- ggplot(weather_data_imputed, \n       aes(x = Max_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Maximum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Maximum Temperature (°C)\")\n\np6\n\n\n\n\nBased on the above observation, as the maximum temperature is not normally distributed, non-parametric test will be used.\n\n\n\np8 &lt;- ggplot(weather_data_imputed, \n       aes(x = Min_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Minimum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Minimum Temperature (°C)\")\n\np8\n\n\n\n\nBased on the above observation, as the minimum temperature is not normally distributed, non-parametric test will be used.\n\n\n\nDefault Non-Parametric tests temperature different per year:\n\nMedian Mean temperature Per YearMedian Max temperature Per YearMedian Min temperature Per Year\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median mean temperature from 2014-2023.\nH1: There is statistical difference between yearly median mean temperature from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_mean_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Mean Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np9\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 19.82 and a p-value of 0.02, which is below the conventional alpha level of 0.05. This suggests that there is statistically significant difference in median maximum temperatures across the years.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median max temperature from 2014-2023.\nH1: There is statistical difference between yearly median max temperature from 2014-2023.\n\np10 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_max_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np10\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 10.02 and a p-value of 0.35, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median min temperature from 2014-2023.\nH1: There is statistical difference between yearly median min temperature from 2014-2023.\n\np11 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_min_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np11\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 14.72 and a p-value of 0.10, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\n\n\nDaily Mean temperatureDaily Max temperatureDaily Min temperature\n\n\nHypothesis :\nH0: There is no statistical difference in daily mean temperature from 2014-2023.\nH1: There is statistical difference in daily mean temperature from 2014-2023.\n\np12 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Mean_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np12\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily max temperature from 2014-2023.\nH1: There is statistical difference in daily max temperature from 2014-2023.\n\np13 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Max_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np13\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily min temperature from 2014-2023.\nH1: There is statistical difference in daily min temperature from 2014-2023.\n\np14 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Min_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np14\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAll daily temperatures (mean, maximum and minimum) have p-value lower than 0.05 which means they all shows statistical significant. Meaning there are statistical different in the mean, maximum and minimum daily temperature in Singapore.\n\nEven though the yearly median max temperature and median min temperature appears no statistical significant, but the daily max and min are statistically different.\n\n\n\n\n\n5.2.1.2 Rainfall\nFor rainfall we will be using the daily rainfall total to test the hypothesis\n\nrainfall_year &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(yearly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nDT::datatable(rainfall_year,class = \"compact\")\n\n\n\n\n\n\n\nwrite_csv(rainfall_year, \"data/rainfall_year.csv\")\n\n\nplot_list &lt;- lapply(unique(rainfall_year$Station), function(stn) {\n  station_data &lt;- subset(rainfall_year, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~yearly_rainfall, name = stn, type = 'scatter', mode = 'lines') %&gt;%\n    layout(title = paste(\"Yearly Rainfall - Station:\", stn),\n           xaxis = list(title = \"Year\", tickangle = 90),\n           yaxis = list(title = \"Rainfall Volume (mm)\"))\n})\n\nfaceted_plot &lt;- subplot(plot_list, nrows = length(unique(rainfall_year$Station)), shareX = TRUE, titleX = FALSE)\n\nfaceted_plot &lt;- layout(faceted_plot,\n                       title = \"Yearly Rainfall Across Weather Stations (2014-2023)\")\nfaceted_plot\n\n\n\n\n\nFrom the observations above, over the pass 10 years from 2014 to 2023 the total rainfall for Singapore captured by different stations indicates there is a volume increase. And every a few years it tend to drop to a low point(2015 and 2019) and will bounce back with even higher volume.\nWe have to check if the different in years of the total rainfall are statistically different, before making any conclusions. But first lets see if the data follows a normal distribution or not in determine the method for test later.\n\np7 &lt;- ggplot(weather_data_imputed, \n       aes(x = Daily_Rainfall_Total_mm, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station) + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Daily Rainfall from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Rainfall Volume (mm)\")\n\np7\n\n\n\n\nFrom the distribution graph using sstat function called stat_density_ridges()of ggplot2. We can see that the rainfall distribution is not normally distributed, so non-parametric test will be used.\n\nMedian Rainfall Per YearMedian Daily Rainfall 2014-2023\n\n\nHypothesis:\nH0: There is no statistical difference between median rainfall per year from 2014-2023.\nH1: There is statistical difference between median rainfall per year across 2014-2023.\n\np8 &lt;- ggbetweenstats(\n  data = rainfall_year,\n  x = Year, \n  y = yearly_rainfall,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np8\n\n\n\n\n\n# Filter the data for a specific year\nrainfall_year_filtered &lt;- rainfall_year %&gt;%\n  filter(Year &gt;= 2014, Year &lt;= 2023)\n\n# Create the plotly violin plot\np8_plotly &lt;- plot_ly(data = rainfall_year_filtered,\n                     x = ~Year,\n                     y = ~yearly_rainfall,\n                     type = 'violin',\n                     spanmode = 'hard',\n                     marker = list(opacity = 0.5, line = list(width = 2)),\n                     box = list(visible = T),\n                     points = 'all',\n                     scalemode = 'count',\n                     meanline = list(visible = T, color = \"red\"),\n                     color = I('#caced8'),\n                     marker = list(line = list(width = 2, color = '#caced8'))\n                    ) %&gt;%\n  layout(title = \"Distribution of Rainfall from 2014 to 2023\",\n         yaxis = list(title = \"Rainfall volume (mm)\"),\n         xaxis = list(title = \"Year\"))\n\n# Show the plot\np8_plotly\n\n\n\n\n\nKruskal-Wallis test result at the top indicates a significant difference in rainfall distribution across the years (p-value &lt; 0.01), suggesting that at least one year has a statistically different total rainfall volume compared to the others.\nfrom the lines connecting the years we can observe that some years trend towards significance when the pHolm-adj is less than 1.00. Hence we can reject the null hypothesis and say that the rainfall over the years is statistically significant.\n\n\nHypothesis:\nH0: There is no statistical difference between median daily rainfall from 2014-2023.\nH1: There is statistical difference between median daily rainfall from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Daily_Rainfall_Total_mm,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np9\n\n\n\n\nWe can dig further into the daily rainfall total to see if there is statistical significant. After undergo the test above, we can observe the test result that overall Kruskal-Wallis test is highly significant (p=2.84e−89), indicating there are differences in the distributions of daily rainfall volumes across the years.\nWe can also observe that some years the median daily rainfall is 0.00 or 0.20 (2014, 2015, 2019, etc.) suggesting low rainfall volume.\n\n\n\n\n\n\n5.2.2 Can We Clearly Identify the ‘Dry’ and ‘Wet’ Month?\nSingapore which is a tropical country, means have no clear identification of the four seasons, but there are certain months which the ‘cooler’ compare to some months. In this section we will be testing the hypothesis on ‘can we clearly identify the ’Dry’ and ‘Wet’ Month’?\nFirst we need to filter the data to get monthly records, code chunk below:\n\nrf_data_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(monthly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nrf_data_month$Year &lt;- factor(rf_data_month$Year)\nrf_data_month$Month &lt;- factor(rf_data_month$Month, levels = as.character(1:12))\n\nDT::datatable(rf_data_month,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(rf_data_month)\n\nRows: 120\nColumns: 3\nGroups: Year [10]\n$ Year             &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014,…\n$ Month            &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5,…\n$ monthly_rainfall &lt;dbl&gt; 450.6, 124.0, 728.1, 1296.2, 1621.8, 1026.9, 1070.8, …\n\n\n\ntemp_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_month,class = \"compact\")\n\n\n\n\n\n\nTo see the distribution of the monthly rainfall and Temperature, code chunk below:\n\nDistribution of Monthly RainfallDistribution of Monthly Mean TemperatureDistribution of Monthly Max TemperatureDistribution of Monthly Min Temperature\n\n\n\ncolor_palette &lt;- brewer.pal(\"Set3\", n = length(unique(rf_data_month$Year)))\n\np18 &lt;- ggplot(rf_data_month, aes(x = Month, y = monthly_rainfall, fill = Year)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title = \"Monthly Rainfall From Year 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Month\") +\n  theme_minimal() +\n  scale_fill_manual(values = color_palette) +\n  theme(panel.spacing.y = unit(0.5, \"lines\")) # Adjusted for less spacing\n\np18\n\n\n\n\nFrom the distribution of monthly rainfall from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np19 &lt;- ggplot(temp_month,\n       aes(y = median_mean_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly mean Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np19\n\n\n\n\nFrom the distribution of monthly mean temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np20 &lt;- ggplot(temp_month,\n       aes(y = median_max_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Maximum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np20\n\n\n\n\nFrom the distribution of monthly maximum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np21 &lt;- ggplot(temp_month,\n       aes(y = median_min_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Minimum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np21\n\n\n\n\nFrom the distribution of monthly minimum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\n\n5.2.2.1 Hypothesis testing\nTo test Monthly Rainfall From Year 2014 to 2023:\nThe hypothesis is as follows:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\nMonthly Rainfall over yearsMonthly Mean TemperatureMonthly Maximum TemperatureMonthly Minimum Temperature\n\n\nHypothesis:\nH0: There is no statistical difference in rainfall volume across months.\nH1: There is statistical difference in rainfall volume across months.\n\np22 &lt;- ggbetweenstats(\n  data = rf_data_month,\n  x = Month, \n  y = monthly_rainfall,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall across months 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Month\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\np22\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the rainfall volume across different month in Singapore.\n\nFeb has significant different in rainfall volume comparing with Nov and Dec.\n2, 3, 7, 8, 9, 10 can consider ‘Dry’ as median rainfall volume lower or equal to around 1000mm per month.\n4, 5, 6, 11, 12 can consider a ‘Wet’ as median rainfall volume mainly higher than 1400mm per month.\n\n\n\nHypothesis:\nH0: There is no statistical difference between mean temperature across months.\nH1: There is statistical difference between mean temperature across months.\n\np23 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_mean_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Mean Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np23\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the mean temperature across different month in Singapore.\n\nIt is observed that towards the middle of the 12 months, 5, 6, 7 ,8 ,9 has the highest median mean temperature .\nWhile months 1, 2, 11, 12 has the lowest median mean temperature.\n\n\n\nHypothesis:\nH0: There is no statistical difference between maximum temperature across months.\nH1: There is statistical difference between maximum temperature across months.\n\np24 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_max_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Maximum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np24\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the maximum temperature across different month in Singapore.\n\nThe month with highest daily temperature is month 3, 4, 5 which average maximum temperature more than 32 Degree Celsius.\nMonth with lowest daily temperature is January, with only average maximum temperature of 30.85 Degree Celsius.\n\n\n\nHypothesis:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\np25 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_min_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Minimum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np25\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the minimum temperature across different month in Singapore.\n\n\n\nFrom the hypothesis testing, result indicates that we can clearly identify the ‘Dry’ or ‘Wet’ months, and also the ‘Hot’ and ‘Cool’ months from the date used.\nFrom the hypothesis testing, several result can be shown:\n\nDry Month: 2, 3, 7, 8, 9\nWet Month :1, 6, 11, 12\nHot Month: 3, 4, 5, 9, 10\nCool Month: 1, 2, 11, 12\nDry & Hot : 3, 9\nWet & Cool : 1, 11, 12\n\nBy identifying this can help Singapore Government to develop strategies to deal with different situations, and also to see the trend in future if there is shift in different type of month"
  }
]